# Алгоритм объединения Excel файлов

## Общая концепция

Приложение работает по принципу **шаблонного объединения**, где базовый файл определяет структуру и правила для всех остальных файлов.

## Входные данные

1. **Базовый файл** - Excel файл, который задает шаблон
2. **Конфигурация** - правила для каждого листа:
   - Имя листа
   - Номер строки с заголовками
   - Флаг включения/выключения
3. **Список файлов** - массив путей к Excel файлам для объединения

## Выходные данные

Excel файл, где каждый лист содержит объединенные данные из соответствующих листов всех входных файлов.

## Детальный алгоритм

Все примеры являются псевдокодом на Python с использованием pandas и openpyxl для понимания алгоритма.

### Фаза 1: Анализ базового файла

```python
def analyze_base_file(base_file_path: Path) -> Dict[str, SheetConfig]:
    """
    Анализ базового файла и создание конфигурации
    
    Шаги:
    1. Открыть базовый файл
    2. Получить список всех листов
    3. Для каждого листа:
       - По умолчанию: enabled=True, header_row=1
       - Пользователь может изменить настройки
    4. Прочитать заголовки из указанной строки
    5. Вернуть конфигурацию
    """
    
    workbook = load_workbook(base_file_path, read_only=True)
    sheet_names = workbook.sheetnames
    
    config = {}
    for sheet_name in sheet_names:
        config[sheet_name] = SheetConfig(
            sheet_name=sheet_name,
            header_row=1,  # По умолчанию первая строка
            enabled=True,
            headers=[]
        )
    
    return config
```

### Фаза 2: Настройка правил пользователем

```
Пользователь для каждого листа:
1. Указывает номер строки с заголовками (1, 2, 3, ...)
2. Видит предпросмотр заголовков
3. Включает/выключает обработку этого листа
```

### Фаза 3: Объединение данных

```python
def merge_files(
    base_file: Path, 
    files: List[Path], 
    config: Dict[str, SheetConfig]
) -> Dict[str, pd.DataFrame]:
    """
    Объединить все файлы согласно конфигурации
    
    Возвращает словарь: {имя_листа: объединенный_DataFrame}
    """
    
    result = {}
    
    # Обрабатываем каждый лист отдельно
    for sheet_name, sheet_config in config.items():
        if not sheet_config.enabled:
            continue  # Пропускаем выключенные листы
        
        # Объединяем данные для этого листа
        result[sheet_name] = merge_single_sheet(
            sheet_name, 
            sheet_config, 
            [base_file] + files  # Базовый файл тоже включаем
        )
    
    return result
```

### Фаза 4: Объединение одного листа

```python
def merge_single_sheet(
    sheet_name: str,
    config: SheetConfig,
    all_files: List[Path]
) -> pd.DataFrame:
    """
    Объединить один лист из всех файлов
    
    Алгоритм:
    1. Прочитать лист из первого файла (базового)
       - Строка с заголовками определена в config.header_row
       - Данные начинаются после строки заголовков
    2. Сохранить заголовки (используем один раз)
    3. Для остальных файлов:
       - Прочитать тот же лист
       - Пропустить строку заголовков
       - Взять только данные
    4. Объединить все данные вертикально (concat)
    5. Вернуть результат
    """
    
    dataframes = []
    headers = None
    
    for i, file_path in enumerate(all_files):
        try:
            # Проверяем наличие листа в файле
            available_sheets = pd.ExcelFile(file_path).sheet_names
            if sheet_name not in available_sheets:
                logger.warning(f"Лист '{sheet_name}' не найден в {file_path.name}")
                continue
            
            # Читаем лист
            # header_row в config - это 1-based (для пользователя)
            # для pandas нужно 0-based, поэтому вычитаем 1
            df = pd.read_excel(
                file_path,
                sheet_name=sheet_name,
                header=config.header_row - 1
            )
            
            # Сохраняем заголовки из первого файла
            if i == 0:
                headers = df.columns.tolist()
            
            # Добавляем данные
            dataframes.append(df)
            
        except Exception as e:
            logger.error(f"Ошибка при чтении {file_path.name}: {e}")
            continue
    
    # Объединяем все DataFrame вертикально
    if dataframes:
        result = pd.concat(dataframes, ignore_index=True)
        return result
    else:
        # Если ни один файл не был обработан, возвращаем пустой DataFrame
        return pd.DataFrame(columns=headers or [])
```

## Примеры

### Пример 1: Простое объединение

**Входные данные:**

Базовый файл: `sales_q1.xlsx`
- Лист "Продажи", строка заголовков: 1
  ```
  | Дата       | Товар  | Сумма |
  |------------|--------|-------|
  | 2024-01-15 | Товар1 | 1000  |
  | 2024-01-20 | Товар2 | 1500  |
  ```

Файл 2: `sales_q2.xlsx`
- Лист "Продажи", строка заголовков: 1
  ```
  | Дата       | Товар  | Сумма |
  |------------|--------|-------|
  | 2024-04-10 | Товар1 | 2000  |
  | 2024-04-15 | Товар3 | 1200  |
  ```

**Результат:**
```
| Дата       | Товар  | Сумма |
|------------|--------|-------|
| 2024-01-15 | Товар1 | 1000  |
| 2024-01-20 | Товар2 | 1500  |
| 2024-04-10 | Товар1 | 2000  |
| 2024-04-15 | Товар3 | 1200  |
```

### Пример 2: Разные строки заголовков

**Входные данные:**

Базовый файл: `report.xlsx`

Лист "Продажи", строка заголовков: 1
```
| Дата       | Товар  | Сумма |
|------------|--------|-------|
| 2024-01-15 | Товар1 | 1000  |
```

Лист "Возвраты", строка заголовков: 2
```
Отчет о возвратах за январь 2024
| Дата       | Номер  | Причина      |
|------------|--------|--------------|
| 2024-01-20 | 12345  | Брак         |
```

**Конфигурация:**
- Продажи: header_row = 1
- Возвраты: header_row = 2

**Результат:**

Лист "Продажи":
```
| Дата       | Товар  | Сумма |
|------------|--------|-------|
| 2024-01-15 | Товар1 | 1000  |
| 2024-02-10 | Товар2 | 1500  |
| ...        | ...    | ...   |
```

Лист "Возвраты":
```
| Дата       | Номер  | Причина      |
|------------|--------|--------------|
| 2024-01-20 | 12345  | Брак         |
| 2024-02-15 | 12346  | Пересорт     |
| ...        | ...    | ...          |
```

### Пример 3: Отсутствие листа в файле

**Сценарий:**
- Базовый файл содержит листы: "Продажи", "Возвраты", "Отчет"
- Файл 2 содержит только: "Продажи", "Возвраты"

**Поведение:**
- Лист "Продажи": объединяются данные из обоих файлов ✓
- Лист "Возвраты": объединяются данные из обоих файлов ✓
- Лист "Отчет": только данные из базового файла ✓
- В лог записывается предупреждение о пропущенном листе

## Обработка особых случаев

### 1. Пустые листы
```python
if df.empty:
    logger.info(f"Лист '{sheet_name}' в {file_path.name} пустой")
    # Пропускаем, не добавляем в список
```

### 2. Разное количество столбцов
```python
# pandas автоматически выравнивает по названиям столбцов
# Если столбец отсутствует - будет NaN
# Если есть лишние столбцы - они тоже включаются
```

### 3. Пропуск пустых строк (опция)
```python
if skip_empty_rows:
    df = df.dropna(how='all')  # Удаляем полностью пустые строки
```

## Производительность

### Оптимизация для больших файлов

```python
# Вместо загрузки всего файла в память
def merge_large_files(files: List[Path], chunk_size: int = 10000):
    """Объединение больших файлов по частям"""
    
    for file_path in files:
        # Читаем файл кусками
        for chunk in pd.read_excel(file_path, chunksize=chunk_size):
            yield chunk  # Обрабатываем по мере чтения
```

### Индикация прогресса

```python
total_operations = len(enabled_sheets) * len(files)
current_operation = 0

for sheet_name in enabled_sheets:
    for file_path in files:
        # Обработка...
        current_operation += 1
        progress_callback(current_operation, total_operations, 
                        f"Обработка {file_path.name}, лист {sheet_name}")
```

## Валидация и проверки

### Перед объединением
1. Все файлы существуют и доступны для чтения
2. Все файлы имеют формат .xlsx
3. Базовый файл содержит хотя бы один лист

### Во время объединения
1. Проверка наличия листа в каждом файле
2. Обработка исключений при чтении
3. Логирование всех предупреждений и ошибок

### После объединения
1. Проверка, что получен хотя бы один непустой DataFrame
2. Подсчет статистики (количество строк, файлов)
